{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67051701-25d7-430e-9249-40da8d58cdcc",
   "metadata": {},
   "source": [
    "# Script de Migración: PayAssistant a Soltura\r\n",
    "\r\n",
    "**Estudiantes:**  \r\n",
    "- Carlos Ávalos Mendieta  \r\n",
    "- Jose Monge Brenes  \r\n",
    "- Daniel Monterrosa Quirós  \r\n",
    "- Sebastian Donoso Chaves  \r\n",
    "\r\n",
    "**Fecha:** 06/05/2025  \r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Descripción\r\n",
    "\r\n",
    "Migración completa de datos desde MySQL (PayAssistant) a SQL Server (Soltura), incluyendo usuarios, permisos, planes de suscripción y configuraciones de pagos.\r\n",
    "\r\n",
    "---\r\n",
    "\r\n",
    "## Estructura del Script\r\n",
    "\r\n",
    "### 1. Conexiones a bases de datos\r\n",
    "Establece la conexión con la base de datos de origen (MySQL) y destino (SQL Server), validando credenciales y conectividad.\r\n",
    "\r\n",
    "### 2. Migración de usuarios y contactos\r\n",
    "Extrae los datos de usuarios y contactos de PayAssistant, los transforma al formato requerido y los inserta en Soltura.\r\n",
    "\r\n",
    "### 3. Migración de roles y permisos\r\n",
    "Migración los distintos roles y permisos asociados a los usuarios para mantener la jerarquía de acceso.\r\n",
    "\r\n",
    "### 4. Migración de planes y suscripciones\r\n",
    "Transfiere los planes de suscripción y sus relaciones con usuarios o empresas al nuevo sistema.\r\n",
    "\r\n",
    "### 5. Migración de schedules y fechas de pago\r\n",
    "Migración la programación de pagos y sus registros históricos asegurando integridad temporal y lógica.\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850dd3c0-a04c-407e-acb5-baa4886c2969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "from sqlalchemy import text\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.dialects.mssql import VARBINARY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcdee223-f08c-49a3-be3e-4176d091d2a3",
   "metadata": {},
   "source": [
    "## Conexión con MySQL\n",
    "\n",
    "En esta sección se definen los datos necesarios para conectarse a la base de datos de origen, que en este caso es MySQL. Se especifican el usuario, la contraseña, el host, el puerto y el nombre de la base de datos. Luego, con esa información, se construye la URL de conexión compatible con SQLAlchemy usando el conector `pymysql`. Finalmente, se crea un \"engine\", que es el objeto que permite interactuar con la base de datos para ejecutar consultas y extraer los datos que se van a migrar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a17ba71-a5d8-4b0d-90d5-33bf3bcb682b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Datos de conexión\n",
    "usuario = \"root\"\n",
    "contrasena = \"root\"\n",
    "host = \"localhost\"\n",
    "puerto = \"6000\"\n",
    "base_datos = \"PayAssistantDB\"\n",
    "\n",
    "# Crea la URL de conexión\n",
    "url = f\"mysql+pymysql://{usuario}:{contrasena}@{host}:{puerto}/{base_datos}\"\n",
    "\n",
    "# Crea el engine\n",
    "engine_mysql = create_engine(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7939cf67-780a-464b-812d-983257714d0b",
   "metadata": {},
   "source": [
    "## Conexión con SQL Server\n",
    "\n",
    "\r\n",
    "En esta parte se establece la conexión con la base de datos de destino, que está en SQL Server. Se usa una cadena de conexión que emplea autenticación de Windows (Trusted Connection), lo cual permite conectarse sin necesidad de usuario y contraseña, siempre que el sistema operativo tenga los permisos necesarios. Se indica también el driver ODBC requerido. Finalmente, se crea un \"engine\" con SQLAlchemy para poder realizar operaciones con esa base de datos durante la migración.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d0f5c6-d621-4df7-b364-ce91d8b2ac9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cadena de conexión usando Trusted Connection (Windows Authentication)\n",
    "connection_string = (\n",
    "    \"mssql+pyodbc://localhost/SolturaDB?driver=ODBC+Driver+17+for+SQL+Server&trusted_connection=yes\"\n",
    ")\n",
    "# Crea el engine\n",
    "sqlserver_engine = create_engine(connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a0326-183d-401b-afab-5a008ebf3994",
   "metadata": {},
   "source": [
    "### Migración de Tabla Usuarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a36e84-37ec-483b-be0c-eeb362fa05df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_sql(\"SELECT * FROM paya_users\", engine_mysql)\n",
    "\n",
    "# Limpiar los bits a enteros\n",
    "df['enable'] = df['enable'].apply(lambda x: int.from_bytes(x, 'little') if isinstance(x, bytes) else x)\n",
    "\n",
    "# Convierte a 1 o 0 explícitamente\n",
    "df['enable'] = df['enable'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af08e347-1b9c-49a0-991e-f387bdca73b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nuevo DataFrame solo con columnas necesarias para sol_users\n",
    "df_users = pd.DataFrame({\n",
    "    'username': df['username'],\n",
    "    'firstname': df['fname'],\n",
    "    'lastname': df['lname'],\n",
    "    'email': df['email'],\n",
    "    'password': 0x70617373776F7264,\n",
    "    'isActive': df['enable'],\n",
    "    'addressid': 1  # Ejemplo: usa una dirección dummy o relacionada previamente\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a006a-c779-4d11-893f-7bb815cdaffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertar usuarios en sol_users\n",
    "df_users.to_sql('sol_users', con=sqlserver_engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7269992d-938b-4d21-a90f-d61c1dd8a6f5",
   "metadata": {},
   "source": [
    "### Vincular números de teléfono a contactInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac48ea-9b97-4cac-bf0b-37dce0eaa869",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inserted = pd.read_sql(\"SELECT userid, username FROM sol_users\", sqlserver_engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf911f-1fe5-466b-b9a2-a98c3e8bc073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_inserted, on='username', how='inner', suffixes=('', '_new'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abc77e6-b418-4264-bf03-7d1737d42c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contact_type = pd.read_sql(\"\"\"SELECT contact_typeid \n",
    "    FROM sol_contact_types \n",
    "    WHERE name = 'Teléfono'\n",
    "    \"\"\", sqlserver_engine)\n",
    "contact_type_id = df_contact_type['contact_typeid'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae5db46-0bc9-40a5-af21-5a736394f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contact_info = pd.DataFrame({\n",
    "    'value': df['phone'],\n",
    "    'notes': ['Teléfono principal'] * len(df),\n",
    "    'enabled': df['enable'],\n",
    "    'userid': df['userid_new'],\n",
    "    'contact_typeid': contact_type_id\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc491dd-327a-45ac-bf3c-9ffb506a9fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_contact_info.to_sql('sol_contact_info', con=sqlserver_engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b8970-c73f-4eb3-b6e0-fd183e6b7813",
   "metadata": {},
   "source": [
    "### Establecer migraciones en una tabla distinta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e7dd5e-0625-44ad-82c5-1fef4389867f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los IDs de los usuarios recién insertados (esto requiere que no haya otros inserts en medio)\n",
    "with sqlserver_engine.connect() as conn:\n",
    "    result = conn.execute(text(f\"SELECT TOP {len(df_users)} userid FROM sol_users ORDER BY userid DESC\"))\n",
    "    inserted_ids = [row[0] for row in result.fetchall()][::-1]  # Invertir para que estén en orden de inserción\n",
    "\n",
    "# Crear DataFrame para sol_migrated_users\n",
    "df_migrated = pd.DataFrame({\n",
    "    'userid': inserted_ids,\n",
    "    'platform_name': ['Payment Assistant'] * len(inserted_ids),\n",
    "    'password_changed': [0] * len(inserted_ids)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd3461b-ddc4-446d-b5f4-1ebc89429f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_migrated.to_sql('sol_migrated_users', con=sqlserver_engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe5ff6-deec-4fed-bc5c-d9fb31044cd3",
   "metadata": {},
   "source": [
    "## Migración de roles y permisos de usuario"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9c21ed-6768-45f2-821a-1ac548b0057f",
   "metadata": {},
   "source": [
    "#### Migración de modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec1e02-16fb-4fb4-8d9c-1a808ff450a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Migrar módulos primero (sin incluir la columna de identidad)\n",
    "df_modules = pd.read_sql(\"SELECT * FROM paya_modules\", engine_mysql)\n",
    "# Eliminar la columna moduleid ya que es IDENTITY en SQL Server\n",
    "df_modules = df_modules[['name']]\n",
    "df_modules.to_sql('sol_modules', con=sqlserver_engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92058492-5598-4a26-aa77-f572959fadfc",
   "metadata": {},
   "source": [
    "#### Migración de roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22d889-e056-4cf2-86f1-ea6cb6d262f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roles = pd.read_sql(\"SELECT rolename, description, asignationdate, is_system_role FROM paya_roles\", engine_mysql)\n",
    "# Convertir BIT a INT para SQL Server\n",
    "df_roles['is_system_role'] = df_roles['is_system_role'].apply(lambda x: int.from_bytes(x, 'little')) if isinstance(df_roles['is_system_role'].iloc[0], bytes) else df_roles['is_system_role'].astype(int)\n",
    "df_roles.to_sql('sol_roles', con=sqlserver_engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d41971-116a-4ce1-b5ef-293f39611a19",
   "metadata": {},
   "source": [
    "#### Migración de permisos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c5424b-2aa2-4286-a318-5f8eb3b4b6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Migrar permisos (dependen de módulos)\n",
    "df_permissions = pd.read_sql(\"\"\"\n",
    "    SELECT p.*, m.moduleid as new_moduleid \n",
    "    FROM paya_permissions p\n",
    "    JOIN paya_modules m ON p.moduleid = m.moduleid\n",
    "\"\"\", engine_mysql)\n",
    "# Solo mantener las columnas necesarias para SQL Server\n",
    "df_permissions = df_permissions[['permissioncode', 'description', 'htmlObjectid', 'new_moduleid']]\n",
    "df_permissions.rename(columns={'new_moduleid': 'moduleid'}, inplace=True)\n",
    "df_permissions.to_sql('sol_permissions', con=sqlserver_engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f4ee43-5a66-4209-b9d7-7af260bdc11c",
   "metadata": {},
   "source": [
    "#### Migración de permisos por rol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bceab3a-86f3-452e-b8da-9bed431bbfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Migrar roles-permisos (dependen de roles y permisos)\n",
    "# Primero necesitamos mapear los IDs antiguos a los nuevos\n",
    "with sqlserver_engine.connect() as conn:\n",
    "    # Obtener mapeo de roles\n",
    "    result = conn.execute(text(\"SELECT roleid, rolename FROM sol_roles\"))\n",
    "    role_map = {row[1]: row[0] for row in result.fetchall()}\n",
    "    \n",
    "    # Obtener mapeo de permisos\n",
    "    result = conn.execute(text(\"SELECT permissionid, permissioncode FROM sol_permissions\"))\n",
    "    permission_map = {row[1]: row[0] for row in result.fetchall()}\n",
    "\n",
    "# Obtener datos originales de MySQL\n",
    "df_roles_permissions = pd.read_sql(\"\"\"\n",
    "    SELECT rp.*, r.rolename, p.permissioncode\n",
    "    FROM paya_rolespermissions rp\n",
    "    JOIN paya_roles r ON rp.roleid = r.roleid\n",
    "    JOIN paya_permissions p ON rp.permissionid = p.permissionid\n",
    "\"\"\", engine_mysql)\n",
    "\n",
    "# Mapear a los nuevos IDs\n",
    "df_roles_permissions['new_roleid'] = df_roles_permissions['rolename'].map(role_map)\n",
    "df_roles_permissions['new_permissionid'] = df_roles_permissions['permissioncode'].map(permission_map)\n",
    "\n",
    "# Preparar datos para SQL Server\n",
    "df_roles_permissions_sql = pd.DataFrame({\n",
    "    'asignationdate': df_roles_permissions['asignationdate'],\n",
    "    'enable': df_roles_permissions['enable'].apply(lambda x: int.from_bytes(x, 'little')) if isinstance(df_roles_permissions['enable'].iloc[0], bytes) else df_roles_permissions['enable'].astype(int),\n",
    "    'deleted': df_roles_permissions['deleted'].apply(lambda x: int.from_bytes(x, 'little')) if isinstance(df_roles_permissions['deleted'].iloc[0], bytes) else df_roles_permissions['deleted'].astype(int),\n",
    "    'lastupdate': df_roles_permissions['lastupdate'],\n",
    "    'checksum': df_roles_permissions['checksum'],\n",
    "    'roleid': df_roles_permissions['new_roleid'],\n",
    "    'permissionid': df_roles_permissions['new_permissionid']\n",
    "})\n",
    "\n",
    "# Filtrar nulos por si hay inconsistencias\n",
    "df_roles_permissions_sql = df_roles_permissions_sql.dropna(subset=['roleid', 'permissionid'])\n",
    "df_roles_permissions_sql.to_sql('sol_rolespermissions', con=sqlserver_engine, if_exists='append', index=False, dtype={'checksum': VARBINARY(250)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5988d7e-c5b0-4a59-afe3-498eaf15aedb",
   "metadata": {},
   "source": [
    "#### Migración de user-roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c4acf-2608-4806-9fd2-1b1852a6fc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Migrar users-roles (dependen de usuarios migrados y roles)\n",
    "# Obtener datos originales de MySQL\n",
    "df_users_roles = pd.read_sql(\"\"\"\n",
    "    SELECT ur.*, r.rolename, u.userid as old_userid\n",
    "    FROM paya_usersroles ur\n",
    "    JOIN paya_roles r ON ur.roleid = r.roleid\n",
    "    JOIN paya_users u ON ur.paya_users_userid = u.userid\n",
    "\"\"\", engine_mysql)\n",
    "\n",
    "# Obtener mapeo de usuarios migrados\n",
    "with sqlserver_engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT userid FROM sol_migrated_users\"))\n",
    "    user_map = {i+1: row[0] for i, row in enumerate(result.fetchall())}  # Asume correlación 1:1 por orden\n",
    "\n",
    "# Mapear a los nuevos IDs\n",
    "df_users_roles['new_userid'] = df_users_roles['old_userid'].map(user_map)\n",
    "df_users_roles['new_roleid'] = df_users_roles['rolename'].map(role_map)\n",
    "\n",
    "# Preparar datos para SQL Server\n",
    "df_users_roles_sql = pd.DataFrame({\n",
    "    'asignationdate': df_users_roles['asginationdate'],  # Nota: corrige nombre de columna si es necesario\n",
    "    'checksum': df_users_roles['checksum'],\n",
    "    'enable': df_users_roles['enable'].apply(lambda x: int.from_bytes(x, 'little')) if isinstance(df_users_roles['enable'].iloc[0], bytes) else df_users_roles['enable'].astype(int),\n",
    "    'deleted': df_users_roles['deleted'].apply(lambda x: int.from_bytes(x, 'little')) if isinstance(df_users_roles['deleted'].iloc[0], bytes) else df_users_roles['deleted'].astype(int),\n",
    "    'roleid': df_users_roles['new_roleid'],\n",
    "    'userid': df_users_roles['new_userid']\n",
    "})\n",
    "\n",
    "# Filtrar nulos por si hay inconsistencias\n",
    "df_users_roles_sql = df_users_roles_sql.dropna(subset=['roleid', 'userid'])\n",
    "df_users_roles_sql.to_sql('sol_usersroles', con=sqlserver_engine, if_exists='append', index=False, dtype={'checksum': VARBINARY(250)})\n",
    "\n",
    "print(\"Migración de roles y permisos completada exitosamente!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546eab21-5284-4d3e-bcde-44add56d5c61",
   "metadata": {},
   "source": [
    "## Migración de planes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826bd0e1-ff31-4c19-b5c5-44b0d18a5c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Migración Simplificada de Planes y Suscripciones\n",
    "\n",
    "df_paya_services = pd.read_sql(\"\"\"\n",
    "    SELECT DISTINCT\n",
    "        s.subscriptionid, \n",
    "        s.description, \n",
    "        pp.amount,\n",
    "        pp.currencyid, \n",
    "        c.acronym as currency,\n",
    "        CASE \n",
    "            WHEN s.description LIKE '%%Netflix%%' THEN 'Streaming'\n",
    "            WHEN s.description LIKE '%%SmartFit%%' THEN 'Deporte'\n",
    "            ELSE 'General' \n",
    "        END as service_type,\n",
    "        pp.planpriceid\n",
    "    FROM paya_subscriptions s\n",
    "    JOIN paya_planprices pp ON s.subscriptionid = pp.subscriptionid\n",
    "    JOIN paya_currencies c ON pp.currencyid = c.currencyid\n",
    "    JOIN paya_scheduledetails sd ON pp.scheduledetailsid = sd.scheduledetailsid\n",
    "    WHERE pp.current = 1\n",
    "\"\"\", engine_mysql)\n",
    "\n",
    "# Mapear tipos de servicio a IDs de Soltura\n",
    "service_type_map = {\n",
    "    'Streaming': 6,  # ID para Streaming en Soltura\n",
    "    'Deporte': 1     # ID para Gimnasios en Soltura\n",
    "}\n",
    "\n",
    "# Crear servicios en Soltura (uno por cada planpriceid)\n",
    "df_sol_services = pd.DataFrame({\n",
    "    'name': 'Migrado - ' + df_paya_services['description'] + ' ' + df_paya_services['planpriceid'].astype(str),\n",
    "    'description': 'Servicio migrado desde PayAssistant: ' + df_paya_services['description'],\n",
    "    'dataType': 'Subscripcion',\n",
    "    'original_amount': df_paya_services['amount'],\n",
    "    'sale_amount': df_paya_services['amount'],\n",
    "    'enabled': 1,\n",
    "    'contractid': 1,\n",
    "    'currencyid': 1,\n",
    "    'servicetypeid': df_paya_services['service_type'].map(service_type_map),\n",
    "    'price_config_id': 1\n",
    "})\n",
    "\n",
    "# Insertar servicios\n",
    "df_sol_services.to_sql('sol_service', con=sqlserver_engine, if_exists='append', index=False)\n",
    "\n",
    "# Obtener IDs insertados usando los nombres únicos que generamos\n",
    "with sqlserver_engine.connect() as conn:\n",
    "    result = conn.execute(\n",
    "        text(\"SELECT serviceid FROM sol_service WHERE name LIKE :pattern\"),\n",
    "        {'pattern': 'Migrado - %'}\n",
    "    )\n",
    "    service_ids = [row[0] for row in result.fetchall()]\n",
    "\n",
    "# Asignar IDs manteniendo el mismo orden de inserción\n",
    "df_paya_services['soltura_service_id'] = service_ids[:len(df_paya_services)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73586af4-a50b-4ae9-9919-79f7bc5aeb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random  # Añade esto al inicio de tu script con los otros imports\n",
    "\n",
    "def create_custom_plans_for_users(df_paya_services):\n",
    "    # Obtener usuarios únicos con sus servicios\n",
    "    df_user_services = pd.read_sql(\"\"\"\n",
    "        SELECT DISTINCT u.userid, s.subscriptionid, s.description,\n",
    "               pp.amount, pp.currencyid, sch.recurrencytype,\n",
    "               sd.basedate, sd.datepart\n",
    "        FROM paya_users u\n",
    "        JOIN paya_plans p ON u.userid = p.userid\n",
    "        JOIN paya_planprices pp ON p.planpriceid = pp.planpriceid\n",
    "        JOIN paya_subscriptions s ON pp.subscriptionid = s.subscriptionid\n",
    "        JOIN paya_scheduledetails sd ON pp.scheduledetailsid = sd.scheduledetailsid\n",
    "        JOIN paya_schedules sch ON sd.scheduleid = sch.scheduleid\n",
    "        WHERE u.enable = 1 AND p.enabled = 1\n",
    "    \"\"\", engine_mysql)\n",
    "\n",
    "    # Mapear a servicios en Soltura\n",
    "    df_user_plans = df_user_services.merge(\n",
    "        df_paya_services[['subscriptionid', 'soltura_service_id']],\n",
    "        on='subscriptionid'\n",
    "    )\n",
    "    \n",
    "    # Crear 1 plan por usuario (agrupando por userid)\n",
    "    df_users_grouped = df_user_plans.groupby('userid').first().reset_index()\n",
    "    \n",
    "    # Crear 1 plan por usuario\n",
    "    df_plans = pd.DataFrame({\n",
    "        'name': 'Plan Personalizado Usuario ' + df_users_grouped['userid'].astype(str),\n",
    "        'description': 'Contiene servicios migrados de PayAssistant',\n",
    "        'customizable': 0,\n",
    "        'limit_people': 1,\n",
    "        'enabled': 1,\n",
    "        'codigoid': 5000 + df_users_grouped.index  # IDs únicos\n",
    "    })\n",
    "    \n",
    "    # Insertar planes y obtener sus IDs\n",
    "    df_plans.to_sql('sol_plans', con=sqlserver_engine, if_exists='append', index=False)\n",
    "    \n",
    "    # Obtener IDs de planes\n",
    "    with sqlserver_engine.connect() as conn:\n",
    "        result = conn.execute(text(\"SELECT planid FROM sol_plans WHERE name LIKE 'Plan Personalizado Usuario %'\"))\n",
    "        plan_ids = [row[0] for row in result.fetchall()]\n",
    "    \n",
    "    df_users_grouped['soltura_planid'] = plan_ids\n",
    "\n",
    "    df_user_plans = df_user_plans.merge(\n",
    "    df_users_grouped[['userid', 'soltura_planid']],\n",
    "    on='userid',\n",
    "    how='left'\n",
    "    )\n",
    "    \n",
    "    # Vincular features (servicios)\n",
    "    plan_features = []\n",
    "    for _, row in df_users_grouped.iterrows():\n",
    "        # Servicio original\n",
    "        plan_features.append({\n",
    "            'value': '1',\n",
    "            'enabled': 1,\n",
    "            'quantitytypeid': 1,\n",
    "            'serviceid': row['soltura_service_id'],\n",
    "            'plantid': row['soltura_planid']\n",
    "        })\n",
    "        \n",
    "        # 2 servicios adicionales\n",
    "        extra_services = pd.read_sql(f\"\"\"\n",
    "            SELECT TOP 2 serviceid FROM sol_service \n",
    "            WHERE serviceid != {row['soltura_service_id']}\n",
    "            ORDER BY NEWID()\n",
    "        \"\"\", sqlserver_engine)['serviceid'].tolist()\n",
    "        \n",
    "        for service_id in extra_services:\n",
    "            plan_features.append({\n",
    "                'value': '1',\n",
    "                'enabled': 1,\n",
    "                'quantitytypeid': 1,\n",
    "                'serviceid': service_id,\n",
    "                'plantid': row['soltura_planid']\n",
    "            })\n",
    "    \n",
    "    # Insertar todos los features\n",
    "    pd.DataFrame(plan_features).to_sql('sol_planfeatures', con=sqlserver_engine, if_exists='append', index=False)\n",
    "    \n",
    "    # Crear precios para los planes (mismo precio que el original)\n",
    "    df_plan_prices = pd.DataFrame({\n",
    "        'amount': df_user_plans['amount'],\n",
    "        'postTime': pd.to_datetime('now'),\n",
    "        'endDate': pd.to_datetime('2030-12-31'),\n",
    "        'current': 1,\n",
    "        'planid': df_user_plans['soltura_planid']\n",
    "    })\n",
    "    df_plan_prices.to_sql('sol_planprices', con=sqlserver_engine, if_exists='append', index=False)\n",
    "    \n",
    "    # Crear suscripciones para los usuarios\n",
    "    df_subscriptions = pd.DataFrame({\n",
    "        'startdate': pd.to_datetime('now'),\n",
    "        'enddate': pd.to_datetime('now') + pd.DateOffset(years=1),\n",
    "        'autorenew': 1,\n",
    "        'statusid': 1,  # Activa\n",
    "        'scheduleid': df_user_plans['recurrencytype'].map({'MONTHLY': 1, 'YEARLY': 3}),  # IDs de schedules en Soltura\n",
    "        'userid': df_user_plans['userid'],\n",
    "        'planid': df_user_plans['soltura_planid']\n",
    "    })\n",
    "    df_subscriptions.to_sql('sol_subscriptions', con=sqlserver_engine, if_exists='append', index=False)\n",
    "    \n",
    "    print(f\"Migración completada: {len(df_users_grouped)} planes creados (1 por usuario)\")\n",
    "\n",
    "create_custom_plans_for_users(df_paya_services)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93d4969-d6df-4e41-bb0e-d261575339e7",
   "metadata": {},
   "source": [
    "### Migración de Schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25b6c51-486f-4369-86af-c312ce195f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def migrate_schedules_and_details(df_paya_services):\n",
    "    # 1. Obtener schedules originales con sus detalles\n",
    "    df_schedules_with_details = pd.read_sql(\"\"\"\n",
    "        SELECT \n",
    "            s.scheduleid as original_scheduleid,\n",
    "            s.name,\n",
    "            s.recurrencytype,\n",
    "            s.repeat,\n",
    "            s.endtype,\n",
    "            s.repetitions,\n",
    "            s.enddate,\n",
    "            sd.scheduledetailsid as original_detailid,\n",
    "            sd.basedate,\n",
    "            sd.datepart,\n",
    "            sd.lastexecution,\n",
    "            sd.nextexecution,\n",
    "            sd.deleted\n",
    "        FROM paya_schedules s\n",
    "        JOIN paya_scheduledetails sd ON s.scheduleid = sd.scheduleid\n",
    "        JOIN paya_planprices pp ON sd.scheduledetailsid = pp.scheduledetailsid\n",
    "        WHERE pp.current = 1\n",
    "    \"\"\", engine_mysql)\n",
    "\n",
    "    # Mapear a estructura de Soltura para schedules principales\n",
    "    df_soltura_schedules = pd.DataFrame({\n",
    "        'name': 'Migrado - ' + df_schedules_with_details['name'],\n",
    "        'description': 'Schedule migrado de PayAssistant - ' + df_schedules_with_details['name'],\n",
    "        'recurrencetypeid': df_schedules_with_details['recurrencytype'].map({\n",
    "            'MONTHLY': 3, 'YEARLY': 5, 'WEEKLY': 2, 'DAILY': 1\n",
    "        }),\n",
    "        'active': 1,\n",
    "        'interval': df_schedules_with_details['recurrencytype'].map({\n",
    "            'MONTHLY': 30, 'YEARLY': 365, 'WEEKLY': 7, 'DAILY': 1\n",
    "        }),\n",
    "        'startdate': pd.to_datetime('now'),\n",
    "        'endtype': df_schedules_with_details['endtype'],\n",
    "        'repetitions': df_schedules_with_details['repetitions']\n",
    "    }).drop_duplicates()\n",
    "\n",
    "    # Insertar schedules y obtener IDs generados\n",
    "    df_soltura_schedules.to_sql('sol_schedules', con=sqlserver_engine, if_exists='append', index=False)\n",
    "    \n",
    "    # Obtener los IDs de los schedules recién insertados\n",
    "    with sqlserver_engine.connect() as conn:\n",
    "        result = conn.execute(\n",
    "            text(\"SELECT scheduleid, name FROM sol_schedules WHERE name LIKE 'Migrado - %'\")\n",
    "        )\n",
    "        schedule_map = {row[1].replace('Migrado - ', ''): row[0] for row in result.fetchall()}\n",
    "\n",
    "    # Preparar los scheduledetails para migración\n",
    "    df_soltura_details = df_schedules_with_details.merge(\n",
    "        pd.DataFrame.from_dict(schedule_map, orient='index', columns=['newscheduleid']),\n",
    "        left_on='name',\n",
    "        right_index=True\n",
    "    )\n",
    "    \n",
    "    # Mapear a estructura de sol_scheduledetails\n",
    "    df_soltura_details_transformed = pd.DataFrame({\n",
    "        'deleted': df_soltura_details['deleted'].apply(lambda x: int.from_bytes(x, 'little') if isinstance(x, bytes) else int(x)),\n",
    "        'basedate': df_soltura_details['basedate'],\n",
    "        'datepart': df_soltura_details['datepart'],\n",
    "        'maxdelaydays': 3,  # Valor por defecto\n",
    "        'executiontime': df_soltura_details['lastexecution'],\n",
    "        'scheduleid': df_soltura_details['newscheduleid'],\n",
    "        'timezone': 'America/Costa_Rica'  # Ajustar según necesidad\n",
    "    })\n",
    "\n",
    "    # Insertar los scheduledetails\n",
    "    df_soltura_details_transformed.to_sql(\n",
    "        'sol_schedulesdetails', \n",
    "        con=sqlserver_engine, \n",
    "        if_exists='append', \n",
    "        index=False\n",
    "    )\n",
    "\n",
    "    # Retornar mapeo de IDs para referencia en otras migraciones\n",
    "    return {\n",
    "        'schedule_map': schedule_map,\n",
    "        'details_map': dict(zip(\n",
    "            df_soltura_details['original_detailid'],\n",
    "            df_soltura_details['newscheduleid']\n",
    "        ))\n",
    "    }\n",
    "\n",
    "schedule_mappings = migrate_schedules_and_details(df_paya_services)\n",
    "\n",
    "# Puedes usar los mapeos después para relacionar otros datos\n",
    "print(f\"Se migraron {len(schedule_mappings['schedule_map'])} schedules\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
